{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a120610a",
   "metadata": {},
   "source": [
    "# Génération des Prédictions et Soumission - Challenge Titanic\n",
    "\n",
    "Ce notebook final vous guide à travers les étapes pour générer des prédictions finales avec votre meilleur modèle et préparer votre soumission pour le challenge Titanic sur Kaggle.\n",
    "\n",
    "## Objectifs:\n",
    "- Charger le meilleur modèle sélectionné après l'évaluation\n",
    "- Générer des prédictions sur l'ensemble de test\n",
    "- Créer un fichier de soumission au format requis par Kaggle\n",
    "- Soumettre les prédictions et analyser les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Configuration de l'affichage\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Pour afficher les graphiques dans le notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Pour afficher toutes les colonnes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00632c80",
   "metadata": {},
   "source": [
    "## 1. Chargement des données prétraitées et du meilleur modèle\n",
    "\n",
    "Commençons par charger les données de test prétraitées et le meilleur modèle identifié lors de l'étape d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bba8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données prétraitées\n",
    "preprocessed_dir = '/workspaces/titanicML/Data/preprocessed'\n",
    "preprocessed_file = os.path.join(preprocessed_dir, 'preprocessed_data.pkl')\n",
    "\n",
    "try:\n",
    "    # Charger les données prétraitées\n",
    "    preprocessed_data = joblib.load(preprocessed_file)\n",
    "    \n",
    "    # Extraire les données de test et les IDs\n",
    "    X_test = preprocessed_data['test_features']\n",
    "    test_passenger_ids = preprocessed_data['test_passenger_ids']\n",
    "    feature_names = preprocessed_data['feature_names']\n",
    "    \n",
    "    print(\"Données de test prétraitées chargées avec succès!\")\n",
    "    print(f\"Ensemble de test: {X_test.shape[0]} observations, {X_test.shape[1]} caractéristiques\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Erreur: Fichier {preprocessed_file} introuvable.\")\n",
    "    print(\"Alternative: chargement des fichiers CSV...\")\n",
    "    \n",
    "    try:\n",
    "        test_file = os.path.join(preprocessed_dir, 'test_processed.csv')\n",
    "        X_test = pd.read_csv(test_file)\n",
    "        \n",
    "        # Récupérer les IDs des passagers de test depuis le fichier d'origine\n",
    "        test_data_original = pd.read_csv('/workspaces/titanicML/Data/test.csv')\n",
    "        test_passenger_ids = test_data_original['PassengerId']\n",
    "        \n",
    "        feature_names = X_test.columns.tolist()\n",
    "        \n",
    "        print(\"Données de test chargées depuis les fichiers CSV.\")\n",
    "        print(f\"Ensemble de test: {X_test.shape[0]} observations, {X_test.shape[1]} caractéristiques\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Erreur: Fichiers CSV également introuvables.\")\n",
    "        print(\"Veuillez exécuter le notebook de prétraitement des données avant de continuer.\")\n",
    "\n",
    "# Rechercher les modèles disponibles\n",
    "models_dir = '/workspaces/titanicML/models'\n",
    "model_files = glob.glob(os.path.join(models_dir, 'final_model_*.pkl'))\n",
    "\n",
    "if model_files:\n",
    "    print(f\"\\nModèles disponibles: {len(model_files)}\")\n",
    "    \n",
    "    # Charger chaque modèle\n",
    "    models = {}\n",
    "    for model_file in model_files:\n",
    "        try:\n",
    "            model_name = os.path.basename(model_file).replace('final_model_', '').replace('.pkl', '').replace('_', ' ')\n",
    "            model_data = joblib.load(model_file)\n",
    "            models[model_name] = model_data\n",
    "            print(f\"  - {model_name} chargé avec succès\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Erreur lors du chargement de {model_file}: {e}\")\n",
    "    \n",
    "    # Vérifier si au moins un modèle a été chargé\n",
    "    if models:\n",
    "        print(\"\\nModèles chargés avec succès!\")\n",
    "    else:\n",
    "        print(\"\\nAucun modèle n'a pu être chargé.\")\n",
    "else:\n",
    "    print(\"\\nAucun modèle trouvé dans le dossier des modèles.\")\n",
    "    print(\"Veuillez exécuter les notebooks de modélisation et d'évaluation avant de continuer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed4472",
   "metadata": {},
   "source": [
    "## 2. Sélection du meilleur modèle pour la soumission finale\n",
    "\n",
    "Identifions le meilleur modèle à utiliser pour notre soumission finale, en nous basant sur les résultats de l'évaluation précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60dc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier s'il existe un modèle d'ensemble qui pourrait être le meilleur choix\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "\n",
    "# Priorité au modèle d'ensemble s'il existe\n",
    "if 'ensemble' in models:\n",
    "    best_model = models['ensemble']['model']\n",
    "    best_model_name = 'Ensemble'\n",
    "    print(\"Le modèle d'ensemble a été sélectionné pour la soumission finale.\")\n",
    "    \n",
    "# Si nous n'avons pas de modèle d'ensemble, charger les fichiers de soumission existants pour voir lequel a été le meilleur\n",
    "else:\n",
    "    submissions_dir = '/workspaces/titanicML/submissions'\n",
    "    submission_files = glob.glob(os.path.join(submissions_dir, 'submission_*.csv'))\n",
    "    \n",
    "    if submission_files and models:\n",
    "        # Si nous avons déjà des soumissions précédentes et des modèles chargés,\n",
    "        # nous pourrions sélectionner le meilleur modèle en fonction d'une évaluation préalable\n",
    "        # Pour cet exemple, nous allons simplement prendre le premier modèle disponible\n",
    "        best_model_name = list(models.keys())[0]\n",
    "        best_model = models[best_model_name]['model']\n",
    "        print(f\"Le modèle '{best_model_name}' a été sélectionné pour la soumission finale.\")\n",
    "    \n",
    "    elif models:\n",
    "        # Si nous n'avons pas de soumissions précédentes mais des modèles chargés\n",
    "        best_model_name = list(models.keys())[0]\n",
    "        best_model = models[best_model_name]['model']\n",
    "        print(f\"Le modèle '{best_model_name}' a été sélectionné pour la soumission finale (premier disponible).\")\n",
    "    \n",
    "    else:\n",
    "        # Si nous n'avons ni soumissions ni modèles, nous devons en créer un\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        print(\"Aucun modèle n'a été trouvé. Création d'un modèle Random Forest par défaut...\")\n",
    "        \n",
    "        # Charger les données d'entraînement\n",
    "        try:\n",
    "            X_train = preprocessed_data['train_features']\n",
    "            y_train = preprocessed_data['train_target']\n",
    "            \n",
    "            # Créer et entraîner un modèle Random Forest simple\n",
    "            best_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            best_model.fit(X_train, y_train)\n",
    "            best_model_name = 'Random Forest (default)'\n",
    "            \n",
    "            print(\"Modèle Random Forest par défaut créé et entraîné avec succès.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la création du modèle par défaut: {e}\")\n",
    "            print(\"Veuillez exécuter les notebooks précédents pour créer des modèles.\")\n",
    "            # Nous ne pouvons pas continuer sans modèle\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a10be",
   "metadata": {},
   "source": [
    "## 3. Génération des prédictions finales\n",
    "\n",
    "Utilisons le meilleur modèle pour générer nos prédictions finales sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que nous avons un modèle et des données de test\n",
    "if best_model is not None and X_test is not None:\n",
    "    # Générer les prédictions\n",
    "    test_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    # Si le modèle peut fournir des probabilités, les récupérer également\n",
    "    if hasattr(best_model, 'predict_proba'):\n",
    "        test_probabilities = best_model.predict_proba(X_test)[:, 1]\n",
    "        has_probabilities = True\n",
    "    else:\n",
    "        test_probabilities = None\n",
    "        has_probabilities = False\n",
    "    \n",
    "    # Créer le DataFrame pour la soumission\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': test_passenger_ids,\n",
    "        'Survived': test_predictions.astype(int)\n",
    "    })\n",
    "    \n",
    "    # Afficher les premières lignes de la soumission\n",
    "    print(\"\\nAperçu des prédictions finales:\")\n",
    "    display(submission.head(10))\n",
    "    \n",
    "    # Statistiques des prédictions\n",
    "    survived_count = submission['Survived'].sum()\n",
    "    total_count = len(submission)\n",
    "    survival_rate = survived_count / total_count * 100\n",
    "    \n",
    "    print(f\"\\nStatistiques des prédictions:\")\n",
    "    print(f\"Nombre de passagers prédits comme survivants: {survived_count} sur {total_count} ({survival_rate:.2f}%)\")\n",
    "    \n",
    "    # Visualiser la distribution des prédictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='Survived', data=submission, palette=['#FF5252', '#4CAF50'])\n",
    "    plt.title('Distribution des prédictions finales', fontsize=16)\n",
    "    plt.xlabel('Prédit comme survivant (0 = Non, 1 = Oui)')\n",
    "    plt.ylabel('Nombre de passagers')\n",
    "    \n",
    "    # Ajouter les annotations sur les barres\n",
    "    counts = submission['Survived'].value_counts()\n",
    "    for i, count in enumerate(counts):\n",
    "        percentage = count / total_count * 100\n",
    "        plt.text(i, count + 5, f'{count} ({percentage:.1f}%)', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Si nous avons les probabilités, afficher leur distribution\n",
    "    if has_probabilities:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=test_probabilities, bins=30, kde=True)\n",
    "        plt.axvline(x=0.5, color='r', linestyle='--', label='Seuil de décision')\n",
    "        plt.title('Distribution des probabilités de survie', fontsize=16)\n",
    "        plt.xlabel('Probabilité de survie')\n",
    "        plt.ylabel('Nombre de passagers')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Impossible de générer des prédictions sans modèle ou données de test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ff4f2",
   "metadata": {},
   "source": [
    "## 4. Création et sauvegarde du fichier de soumission\n",
    "\n",
    "Préparons le fichier de soumission au format requis par Kaggle et sauvegardons-le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a97e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le dossier pour les soumissions s'il n'existe pas\n",
    "submissions_dir = '/workspaces/titanicML/submissions'\n",
    "if not os.path.exists(submissions_dir):\n",
    "    os.makedirs(submissions_dir)\n",
    "\n",
    "# Créer un nom de fichier unique pour cette soumission\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name_safe = best_model_name.replace(' ', '_').lower() if best_model_name else 'unknown_model'\n",
    "submission_file = os.path.join(submissions_dir, f'submission_{model_name_safe}_{timestamp}.csv')\n",
    "\n",
    "# Sauvegarder le fichier de soumission\n",
    "try:\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "    print(f\"Fichier de soumission créé avec succès: {submission_file}\")\n",
    "    \n",
    "    # Créer également une copie avec un nom plus simple pour faciliter le téléchargement\n",
    "    final_submission_file = os.path.join(submissions_dir, 'submission_final.csv')\n",
    "    submission.to_csv(final_submission_file, index=False)\n",
    "    print(f\"Copie créée pour faciliter le téléchargement: {final_submission_file}\")\n",
    "    \n",
    "    # Afficher les premières lignes du fichier pour vérification\n",
    "    print(\"\\nContenu du fichier de soumission:\")\n",
    "    display(pd.read_csv(submission_file).head())\n",
    "    \n",
    "    # Vérifier que le format est correct\n",
    "    expected_columns = ['PassengerId', 'Survived']\n",
    "    if all(col in submission.columns for col in expected_columns):\n",
    "        print(\"\\n✅ Le format du fichier de soumission est correct.\")\n",
    "        print(\"   Colonnes attendues: PassengerId, Survived\")\n",
    "        print(f\"   Nombre de lignes: {len(submission)} (attendu: {len(test_passenger_ids)})\")\n",
    "        \n",
    "        # Vérifier que les valeurs de Survived sont bien 0 ou 1\n",
    "        valid_values = set(submission['Survived'].unique()).issubset({0, 1})\n",
    "        if valid_values:\n",
    "            print(\"   Valeurs de 'Survived' correctes (0 ou 1 uniquement)\")\n",
    "        else:\n",
    "            print(\"❌ Erreur: Les valeurs de 'Survived' doivent être 0 ou 1 uniquement\")\n",
    "    else:\n",
    "        missing_cols = [col for col in expected_columns if col not in submission.columns]\n",
    "        print(f\"\\n❌ Erreur: Format du fichier incorrect. Colonnes manquantes: {missing_cols}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la création du fichier de soumission: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ce57b2",
   "metadata": {},
   "source": [
    "## 5. Soumission à Kaggle\n",
    "\n",
    "Pour soumettre vos prédictions à Kaggle, vous pouvez utiliser l'API Kaggle ou télécharger le fichier `submission_final.csv` et le soumettre manuellement sur le site web de Kaggle.\n",
    "\n",
    "### 5.1 Soumission via l'API Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1094516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que la configuration de l'API Kaggle est disponible\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle_json_path = os.path.join(Path.home(), '.kaggle', 'kaggle.json')\n",
    "\n",
    "if os.path.exists(kaggle_json_path):\n",
    "    print(\"Configuration de l'API Kaggle trouvée!\")\n",
    "    \n",
    "    # Soumission à Kaggle en utilisant l'API\n",
    "    print(\"\\nSoumission des prédictions à Kaggle...\")\n",
    "    \n",
    "    # La commande pour soumettre à Kaggle\n",
    "    submission_command = f\"kaggle competitions submit -c titanic -f {final_submission_file} -m \\\"Submission with {best_model_name} model\\\"\"\n",
    "    \n",
    "    # Exécuter la commande\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(submission_command, shell=True, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n✅ Soumission réussie!\")\n",
    "            print(result.stdout)\n",
    "            \n",
    "            # Vérifier le classement actuel\n",
    "            print(\"\\nVérification du classement actuel...\")\n",
    "            leaderboard_command = \"kaggle competitions leaderboard -c titanic --show\"\n",
    "            leaderboard = subprocess.run(leaderboard_command, shell=True, capture_output=True, text=True)\n",
    "            \n",
    "            if leaderboard.returncode == 0:\n",
    "                print(\"\\nClassement actuel:\")\n",
    "                print(leaderboard.stdout)\n",
    "            else:\n",
    "                print(\"Impossible de récupérer le classement.\")\n",
    "                print(leaderboard.stderr)\n",
    "        else:\n",
    "            print(\"\\n❌ Erreur lors de la soumission:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "            print(\"\\nVous pouvez soumettre manuellement votre fichier en le téléchargeant et en l'important sur le site web de Kaggle.\")\n",
    "            print(f\"Fichier à soumettre: {final_submission_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Erreur lors de l'exécution de la commande: {e}\")\n",
    "        print(\"\\nVous pouvez soumettre manuellement votre fichier en le téléchargeant et en l'important sur le site web de Kaggle.\")\n",
    "        print(f\"Fichier à soumettre: {final_submission_file}\")\n",
    "else:\n",
    "    print(\"\\n❌ Configuration de l'API Kaggle non trouvée.\")\n",
    "    print(\"Pour soumettre vos prédictions, vous pouvez:\")\n",
    "    print(f\"1. Télécharger le fichier {final_submission_file}\")\n",
    "    print(\"2. Visiter https://www.kaggle.com/c/titanic/submit\")\n",
    "    print(\"3. Importer votre fichier de soumission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49780190",
   "metadata": {},
   "source": [
    "## 6. Résumé du projet\n",
    "\n",
    "Récapitulons tout le travail réalisé dans ce projet et les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un résumé du projet\n",
    "print(\"=== RÉSUMÉ DU PROJET TITANIC ===\\n\")\n",
    "\n",
    "# Informations sur les données\n",
    "try:\n",
    "    train_data = pd.read_csv('/workspaces/titanicML/Data/train.csv')\n",
    "    test_data = pd.read_csv('/workspaces/titanicML/Data/test.csv')\n",
    "    \n",
    "    print(f\"Ensemble d'entraînement: {train_data.shape[0]} observations, {train_data.shape[1]} colonnes\")\n",
    "    print(f\"Ensemble de test: {test_data.shape[0]} observations, {test_data.shape[1]} colonnes\")\n",
    "    \n",
    "    # Taux de survie dans les données d'entraînement\n",
    "    survival_rate = train_data['Survived'].mean() * 100\n",
    "    print(f\"\\nTaux de survie dans les données d'entraînement: {survival_rate:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Impossible de charger les données d'origine: {e}\")\n",
    "\n",
    "# Informations sur le prétraitement\n",
    "print(\"\\nPrétraitement des données:\")\n",
    "print(\"- Imputation des valeurs manquantes pour l'âge, le port d'embarquement et le tarif\")\n",
    "print(\"- Création de nouvelles caractéristiques (taille de la famille, groupe d'âge, etc.)\")\n",
    "print(\"- Encodage des variables catégorielles\")\n",
    "print(\"- Normalisation des variables numériques\")\n",
    "\n",
    "# Informations sur les modèles\n",
    "print(\"\\nModèles testés:\")\n",
    "model_list = list(models.keys()) if 'models' in locals() and models else [\"Aucun modèle trouvé\"]\n",
    "for model_name in model_list:\n",
    "    print(f\"- {model_name}\")\n",
    "\n",
    "# Informations sur la soumission finale\n",
    "print(\"\\nSoumission finale:\")\n",
    "if 'submission' in locals() and 'best_model_name' in locals() and best_model_name:\n",
    "    print(f\"- Modèle utilisé: {best_model_name}\")\n",
    "    print(f\"- Taux de survie prédit: {submission['Survived'].mean()*100:.2f}%\")\n",
    "    print(f\"- Fichier de soumission: {final_submission_file}\")\n",
    "else:\n",
    "    print(\"- Aucune soumission générée\")\n",
    "\n",
    "print(\"\\n=== FIN DU PROJET TITANIC ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73645e",
   "metadata": {},
   "source": [
    "## 7. Prochaines étapes et améliorations possibles\n",
    "\n",
    "Voici quelques pistes pour améliorer davantage vos performances dans le challenge Titanic:\n",
    "\n",
    "### Améliorations du prétraitement des données:\n",
    "- Tester différentes stratégies d'imputation pour les valeurs manquantes\n",
    "- Créer des caractéristiques plus complexes basées sur des interactions entre variables\n",
    "- Explorer des techniques de sélection automatique des caractéristiques\n",
    "\n",
    "### Améliorations des modèles:\n",
    "- Tester d'autres algorithmes avancés comme les réseaux de neurones\n",
    "- Optimiser davantage les hyperparamètres avec une recherche plus exhaustive\n",
    "- Créer des ensembles plus sophistiqués combinant différents types de modèles\n",
    "- Utiliser des techniques de validation croisée imbriquées pour une meilleure généralisation\n",
    "\n",
    "### Améliorations de la soumission:\n",
    "- Analyser les erreurs communes entre plusieurs modèles pour identifier des patterns\n",
    "- Ajuster le seuil de décision pour optimiser le score sur Kaggle\n",
    "- Tester plusieurs soumissions avec différents modèles et configurations\n",
    "\n",
    "### Approfondissement de l'analyse:\n",
    "- Explorer davantage les relations entre les variables et la survie\n",
    "- Analyser les règles de décision apprises par les modèles\n",
    "- Étudier la littérature historique sur le naufrage du Titanic pour incorporer des connaissances externes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d499c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Félicitations! Vous avez maintenant complété l'ensemble du processus d'analyse et de prédiction pour le challenge Titanic sur Kaggle:\n",
    "\n",
    "1. **Analyse exploratoire des données**: Vous avez exploré en détail les caractéristiques des passagers et leurs relations avec la survie\n",
    "2. **Prétraitement des données**: Vous avez transformé les données brutes en caractéristiques exploitables par les modèles\n",
    "3. **Modélisation**: Vous avez testé et optimisé différents algorithmes de machine learning\n",
    "4. **Évaluation**: Vous avez analysé en profondeur les performances des modèles\n",
    "5. **Soumission**: Vous avez généré des prédictions et soumis vos résultats à Kaggle\n",
    "\n",
    "Ce projet vous a permis de mettre en pratique l'ensemble du cycle de vie d'un projet de science des données, de l'exploration initiale à la soumission finale. Les compétences acquises dans ce challenge peuvent être appliquées à de nombreux autres problèmes de classification en science des données.\n",
    "\n",
    "N'hésitez pas à explorer les nombreuses ressources disponibles dans la communauté Kaggle pour continuer à améliorer vos performances sur ce challenge classique du machine learning!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
