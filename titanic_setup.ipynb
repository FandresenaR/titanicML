{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a082d4",
   "metadata": {},
   "source": [
    "# Configuration du Codespace pour le Challenge Titanic\n",
    "\n",
    "Ce notebook va vous aider à configurer votre environnement de travail pour le challenge Titanic sur Kaggle. Nous allons installer les dépendances nécessaires, télécharger les données et vérifier que tout est prêt pour commencer l'analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9b460",
   "metadata": {},
   "source": [
    "## 1. Vérification et installation des dépendances nécessaires\n",
    "\n",
    "Nous allons d'abord vérifier et installer toutes les bibliothèques Python nécessaires pour notre analyse de données et nos modèles de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91c9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.2.6)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.6.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in /home/codespace/.local/lib/python3.12/site-packages (0.13.2)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: bleach in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (3.10)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kaggle) (4.66.2)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (0.5.1)\n",
      "Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Installing collected packages: text-unidecode, python-slugify, protobuf, numpy, pandas, kaggle, scikit-learn\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling pandas-2.2.3:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.30m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/7\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [kaggle]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.6.1╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m6/7\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.6.1:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m6/7\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.6.10m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m6/7\u001b[0m [scikit-learn]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed kaggle-1.7.4.5 numpy-2.3.1 pandas-2.3.0 protobuf-6.31.1 python-slugify-8.0.4 scikit-learn-1.7.0 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "# Installation des bibliothèques essentielles pour l'analyse des données et le machine learning\n",
    "!pip install -U pandas numpy scikit-learn matplotlib seaborn kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82d4fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.0\n",
      "numpy version: 2.3.1\n",
      "scikit-learn version: 1.7.0\n",
      "matplotlib version: 3.10.3\n",
      "seaborn version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "# Vérification des versions des bibliothèques installées\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"scikit-learn version: {sklearn_version}\")\n",
    "print(f\"matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54510eb6",
   "metadata": {},
   "source": [
    "## 2. Configuration de l'API Kaggle et téléchargement des données\n",
    "\n",
    "Pour télécharger les données du challenge Titanic directement depuis Kaggle, nous devons configurer l'API Kaggle. Pour cela, vous aurez besoin d'un fichier `kaggle.json` contenant votre nom d'utilisateur et votre clé API.\n",
    "\n",
    "Si vous n'avez pas encore ce fichier:\n",
    "1. Connectez-vous à votre compte Kaggle\n",
    "2. Allez dans \"Mon compte\" (My Account)\n",
    "3. Faites défiler vers le bas jusqu'à la section API\n",
    "4. Cliquez sur \"Créer un nouveau jeton d'API\" (Create New API Token)\n",
    "5. Un fichier kaggle.json sera téléchargé, vous pouvez l'uploader dans votre codespace\n",
    "\n",
    "Si vous avez déjà le fichier kaggle.json, exécutez la cellule suivante pour le configurer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924e3f9",
   "metadata": {},
   "source": [
    "**Note importante**: Vous avez déjà un fichier `kaggle.json` à la racine de votre workspace. Nous allons l'utiliser directement plutôt que de vous demander d'en télécharger un nouveau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire /home/codespace/.kaggle créé avec succès.\n",
      "Pour utiliser l'API Kaggle, placez votre fichier kaggle.json dans ce répertoire.\n"
     ]
    }
   ],
   "source": [
    "# Configuration du répertoire Kaggle et copie du fichier kaggle.json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Chemin du répertoire .kaggle dans le dossier utilisateur\n",
    "kaggle_dir = Path.home() / '.kaggle'\n",
    "\n",
    "# Créer le répertoire .kaggle s'il n'existe pas\n",
    "if not os.path.exists(kaggle_dir):\n",
    "    os.makedirs(kaggle_dir)\n",
    "    print(f\"Répertoire {kaggle_dir} créé avec succès.\")\n",
    "else:\n",
    "    print(f\"Le répertoire {kaggle_dir} existe déjà.\")\n",
    "\n",
    "# Chemin du fichier kaggle.json dans le workspace\n",
    "kaggle_json_source = \"/workspaces/titanicML/kaggle.json\"\n",
    "kaggle_json_dest = os.path.join(kaggle_dir, \"kaggle.json\")\n",
    "\n",
    "# Copier le fichier kaggle.json s'il existe\n",
    "if os.path.exists(kaggle_json_source):\n",
    "    shutil.copy2(kaggle_json_source, kaggle_json_dest)\n",
    "    print(f\"Fichier kaggle.json copié avec succès vers {kaggle_json_dest}\")\n",
    "    \n",
    "    # Modifier les permissions pour que Kaggle l'accepte\n",
    "    os.chmod(kaggle_json_dest, 0o600)\n",
    "    print(\"Permissions du fichier kaggle.json mises à jour\")\n",
    "    \n",
    "    print(\"\\nConfiguration de l'API Kaggle terminée avec succès!\")\n",
    "else:\n",
    "    print(f\"Fichier kaggle.json introuvable dans {kaggle_json_source}\")\n",
    "    print(\"Veuillez placer votre fichier kaggle.json à la racine du projet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43cc422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration de l'API Kaggle trouvée!\n",
      "Décommenter la ligne ci-dessous pour télécharger les données:\n",
      "!kaggle competitions download -c titanic -p ../Data\n",
      "\n",
      "Vérification des fichiers de données existants...\n",
      "✗ Le fichier train.csv n'existe pas!\n",
      "✗ Le fichier test.csv n'existe pas!\n",
      "✗ Le fichier gender_submission.csv n'existe pas!\n",
      "\n",
      "Certains fichiers de données sont manquants. Vous pouvez utiliser l'API Kaggle pour les télécharger.\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la configuration de l'API Kaggle\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle_json_path = os.path.join(Path.home(), '.kaggle', 'kaggle.json')\n",
    "\n",
    "if os.path.exists(kaggle_json_path):\n",
    "    print(\"Configuration de l'API Kaggle trouvée!\")\n",
    "    print(\"Décommenter la ligne ci-dessous pour télécharger les données:\")\n",
    "    print(\"!kaggle competitions download -c titanic -p ../Data\")\n",
    "else:\n",
    "    print(\"Configuration de l'API Kaggle non trouvée.\")\n",
    "\n",
    "# Alternative: nous avons déjà les données dans le dossier Data\n",
    "print(\"\\nVérification des fichiers de données existants...\")\n",
    "\n",
    "data_dir = \"../Data\"\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "test_file = os.path.join(data_dir, \"test.csv\")\n",
    "submission_file = os.path.join(data_dir, \"gender_submission.csv\")\n",
    "\n",
    "files_exist = True\n",
    "for file_path in [train_file, test_file, submission_file]:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"✓ Le fichier {os.path.basename(file_path)} existe.\")\n",
    "    else:\n",
    "        print(f\"✗ Le fichier {os.path.basename(file_path)} n'existe pas!\")\n",
    "        files_exist = False\n",
    "\n",
    "if files_exist:\n",
    "    print(\"\\nTous les fichiers de données nécessaires sont disponibles!\")\n",
    "else:\n",
    "    print(\"\\nCertains fichiers de données sont manquants. Vous pouvez utiliser l'API Kaggle pour les télécharger.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ace075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification du contenu du fichier kaggle.json\n",
    "import json\n",
    "\n",
    "kaggle_json_path = os.path.join(Path.home(), '.kaggle', 'kaggle.json')\n",
    "\n",
    "if os.path.exists(kaggle_json_path):\n",
    "    try:\n",
    "        with open(kaggle_json_path, 'r') as f:\n",
    "            kaggle_config = json.load(f)\n",
    "        \n",
    "        # Vérifier que les clés requises sont présentes (sans afficher les valeurs sensibles)\n",
    "        required_keys = ['username', 'key']\n",
    "        keys_present = all(key in kaggle_config for key in required_keys)\n",
    "        \n",
    "        if keys_present:\n",
    "            print(\"✓ Fichier kaggle.json correctement formaté avec toutes les clés requises.\")\n",
    "            print(f\"✓ Utilisateur Kaggle configuré: {kaggle_config.get('username')}\")\n",
    "            # On ne montre pas la clé API pour des raisons de sécurité\n",
    "            print(\"✓ Clé API présente\")\n",
    "        else:\n",
    "            print(\"✗ Fichier kaggle.json mal formaté - clés manquantes.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"✗ Le fichier kaggle.json n'est pas un JSON valide.\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Erreur lors de la lecture du fichier kaggle.json: {e}\")\n",
    "else:\n",
    "    print(\"✗ Fichier kaggle.json non trouvé dans ~/.kaggle/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16baec52",
   "metadata": {},
   "source": [
    "## 3. Chargement et exploration des fichiers de données\n",
    "\n",
    "Maintenant que nous avons vérifié la présence des fichiers de données, chargeons-les avec pandas pour les explorer rapidement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de897bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les données depuis Kaggle si elles sont manquantes\n",
    "import os\n",
    "\n",
    "data_dir = \"../Data\"\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "test_file = os.path.join(data_dir, \"test.csv\")\n",
    "missing_files = not (os.path.exists(train_file) and os.path.exists(test_file))\n",
    "\n",
    "# Créer le répertoire Data s'il n'existe pas\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"Dossier {data_dir} créé.\")\n",
    "\n",
    "if missing_files and os.path.exists(os.path.join(Path.home(), '.kaggle', 'kaggle.json')):\n",
    "    print(\"Certains fichiers de données sont manquants. Téléchargement depuis Kaggle...\")\n",
    "    \n",
    "    # Décommentez la ligne ci-dessous pour télécharger les données\n",
    "    # !kaggle competitions download -c titanic -p {data_dir} --force\n",
    "    \n",
    "    # Pour extraire les fichiers zip téléchargés\n",
    "    # !unzip -o {os.path.join(data_dir, \"titanic.zip\")} -d {data_dir}\n",
    "    \n",
    "    print(\"\\nInstructions pour télécharger manuellement:\")\n",
    "    print(\"1. Exécutez: kaggle competitions download -c titanic -p ../Data\")\n",
    "    print(\"2. Puis:     unzip -o ../Data/titanic.zip -d ../Data\")\n",
    "else:\n",
    "    print(\"Les fichiers de données existent déjà ou la configuration Kaggle n'est pas disponible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données d'entraînement\n",
    "try:\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    print(f\"Données d'entraînement chargées : {train_data.shape[0]} lignes et {train_data.shape[1]} colonnes\\n\")\n",
    "    \n",
    "    # Afficher les premières lignes\n",
    "    print(\"Aperçu des données d'entraînement :\")\n",
    "    display(train_data.head())\n",
    "    \n",
    "    # Information sur les types de colonnes\n",
    "    print(\"\\nInformations sur les colonnes :\")\n",
    "    display(train_data.info())\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    print(\"\\nStatistiques descriptives :\")\n",
    "    display(train_data.describe())\n",
    "    \n",
    "    # Valeurs manquantes\n",
    "    print(\"\\nValeurs manquantes par colonne :\")\n",
    "    missing_values = train_data.isnull().sum()\n",
    "    missing_percent = (missing_values / len(train_data)) * 100\n",
    "    missing_df = pd.DataFrame({'Nombre de valeurs manquantes': missing_values,\n",
    "                             'Pourcentage (%)': missing_percent})\n",
    "    display(missing_df[missing_df['Nombre de valeurs manquantes'] > 0].sort_values('Nombre de valeurs manquantes', ascending=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données d'entraînement: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae327f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données de test\n",
    "try:\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    print(f\"Données de test chargées : {test_data.shape[0]} lignes et {test_data.shape[1]} colonnes\\n\")\n",
    "    \n",
    "    # Afficher les premières lignes\n",
    "    print(\"Aperçu des données de test :\")\n",
    "    display(test_data.head())\n",
    "    \n",
    "    # Valeurs manquantes dans les données de test\n",
    "    print(\"\\nValeurs manquantes par colonne (données de test) :\")\n",
    "    test_missing_values = test_data.isnull().sum()\n",
    "    test_missing_percent = (test_missing_values / len(test_data)) * 100\n",
    "    test_missing_df = pd.DataFrame({'Nombre de valeurs manquantes': test_missing_values,\n",
    "                                 'Pourcentage (%)': test_missing_percent})\n",
    "    display(test_missing_df[test_missing_df['Nombre de valeurs manquantes'] > 0].sort_values('Nombre de valeurs manquantes', ascending=False))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données de test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f52d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le format du fichier de soumission\n",
    "try:\n",
    "    submission_example = pd.read_csv(submission_file)\n",
    "    print(\"Format du fichier de soumission :\")\n",
    "    display(submission_example.head())\n",
    "    print(f\"\\nLe fichier de soumission contient {submission_example.shape[0]} lignes et {submission_example.shape[1]} colonnes\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du fichier d'exemple de soumission: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40fbb9",
   "metadata": {},
   "source": [
    "## 4. Configuration de la structure du projet\n",
    "\n",
    "Créons une structure de dossiers organisée pour notre projet Titanic ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e41cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des dossiers pour organiser notre projet\n",
    "project_structure = [\n",
    "    \"notebooks\",     # Pour stocker les différents notebooks d'analyse\n",
    "    \"models\",        # Pour sauvegarder les modèles entrainés\n",
    "    \"submissions\",   # Pour les fichiers de soumission à Kaggle\n",
    "    \"src\"           # Pour le code source réutilisable\n",
    "]\n",
    "\n",
    "for folder in project_structure:\n",
    "    folder_path = os.path.join(\"/workspaces/titanicML\", folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Dossier '{folder}' créé.\")\n",
    "    else:\n",
    "        print(f\"Le dossier '{folder}' existe déjà.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c06251",
   "metadata": {},
   "source": [
    "## 5. Résumé et prochaines étapes\n",
    "\n",
    "Nous avons maintenant:\n",
    "- Installé les bibliothèques nécessaires pour l'analyse de données et le machine learning\n",
    "- Vérifié l'accès aux données du challenge Titanic\n",
    "- Exploré brièvement les ensembles de données\n",
    "- Créé une structure de projet organisée\n",
    "\n",
    "### Prochaines étapes\n",
    "1. **Analyse exploratoire des données**: Créer un notebook d'analyse approfondie pour comprendre les relations entre les variables\n",
    "2. **Prétraitement des données**: Gérer les valeurs manquantes, créer de nouvelles caractéristiques, encoder les variables catégorielles\n",
    "3. **Modélisation**: Tester différents algorithmes de classification (Random Forest, XGBoost, etc.)\n",
    "4. **Évaluation**: Mesurer les performances des modèles\n",
    "5. **Soumission**: Générer des prédictions pour les données de test et les soumettre à Kaggle\n",
    "\n",
    "Vous êtes maintenant prêt à commencer à travailler sur le challenge Titanic!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
